{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505cedd7-32d1-4c8d-b03f-6126a478067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers datasets torch tensorflow scikit-learn gradio pandas numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb0eab-4db1-4a53-bf7f-23838252b513",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225ce3fb-c923-41e8-98a9-6c61270732b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/train.csv\", names=[\"Question\", \"Answer\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee82c67-14e8-49dc-98a3-9d5b908db95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Question  \\\n",
      "qtype                                                     Question   \n",
      "susceptibility   Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "symptoms         What are the symptoms of Lymphocytic Choriomen...   \n",
      "susceptibility   Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "exams and tests  How to diagnose Lymphocytic Choriomeningitis (...   \n",
      "\n",
      "                                                            Answer  \n",
      "qtype                                                       Answer  \n",
      "susceptibility   LCMV infections can occur after exposure to fr...  \n",
      "symptoms         LCMV is most commonly recognized as causing ne...  \n",
      "susceptibility   Individuals of all ages who come into contact ...  \n",
      "exams and tests  During the first phase of the disease, the mos...  \n",
      "                                                      Question  \\\n",
      "symptoms     What are the symptoms of Familial visceral myo...   \n",
      "information              What is (are) Pseudopelade of Brocq ?   \n",
      "symptoms      What are the symptoms of Pseudopelade of Brocq ?   \n",
      "treatment    What are the treatments for Pseudopelade of Br...   \n",
      "information  What is (are) Desmoplastic small round cell tu...   \n",
      "\n",
      "                                                        Answer  \n",
      "symptoms     What are the signs and symptoms of Familial vi...  \n",
      "information  Pseudopelade of Brocq (PBB) is a slowly progre...  \n",
      "symptoms     What are the signs and symptoms of Pseudopelad...  \n",
      "treatment    Is there treatment or a cure for pseudopelade ...  \n",
      "information  Desmoplastic small round cell tumors (DSRCT), ...  \n"
     ]
    }
   ],
   "source": [
    "# Display dataset sample\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50f2202-df79-4549-8ecf-8bc0468bed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73eb2119-5bb9-4211-bffc-be008048848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Question', 'Answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283e61d7-0f80-488e-aae8-827e4c9c63f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "                                                          Question  \\\n",
      "qtype                                                     Question   \n",
      "susceptibility   Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "symptoms         What are the symptoms of Lymphocytic Choriomen...   \n",
      "susceptibility   Who is at risk for Lymphocytic Choriomeningiti...   \n",
      "exams and tests  How to diagnose Lymphocytic Choriomeningitis (...   \n",
      "\n",
      "                                                            Answer  \n",
      "qtype                                                       Answer  \n",
      "susceptibility   LCMV infections can occur after exposure to fr...  \n",
      "symptoms         LCMV is most commonly recognized as causing ne...  \n",
      "susceptibility   Individuals of all ages who come into contact ...  \n",
      "exams and tests  During the first phase of the disease, the mos...  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16408 entries, qtype to information\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  16408 non-null  object\n",
      " 1   Answer    16408 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 384.6+ KB\n",
      "None\n",
      "\n",
      "Descriptive Statistics:\n",
      "                                Question  \\\n",
      "count                              16408   \n",
      "unique                             14980   \n",
      "top     What causes Causes of Diabetes ?   \n",
      "freq                                  20   \n",
      "\n",
      "                                                   Answer  \n",
      "count                                               16408  \n",
      "unique                                              15818  \n",
      "top     This condition is inherited in an autosomal re...  \n",
      "freq                                                  348  \n",
      "\n",
      "Missing Values:\n",
      "Question    0\n",
      "Answer      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the structure\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the structure of the DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Get descriptive statistics for a quick numerical overview\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e94e6b-4957-48f2-9e66-d74281bca89f",
   "metadata": {},
   "source": [
    "# Preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7074aaab-47af-472c-a224-20447004cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [11860, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [11801, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the model name\n",
    "MODEL_NAME = \"t5-small\"  \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenization function for sequence-to-sequence training\n",
    "def tokenize_function(row):\n",
    "    # Tokenize the question (input)\n",
    "    model_inputs = tokenizer(row[\"Question\"],\n",
    "                               padding=\"max_length\",\n",
    "                               truncation=True,\n",
    "                               max_length=512)\n",
    "    # Tokenize the answer (target) separately\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(row[\"Answer\"],\n",
    "                           padding=\"max_length\",\n",
    "                           truncation=True,\n",
    "                           max_length=512)\n",
    "    # Assign labels (target token ids) to the input dictionary\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization to each row of the DataFrame\n",
    "# This produces a Series of dictionaries\n",
    "tokenized_data = df.apply(tokenize_function, axis=1)\n",
    "tokenized_examples = tokenized_data.tolist()  # Convert to a list if needed\n",
    "\n",
    "#  Print one example to inspect\n",
    "print(tokenized_examples[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfcac118-1651-4781-8bab-1627d5ceb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into training and validation sets (80% train, 20% validation)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"Question\"], df[\"Answer\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text to tokenized input IDs\n",
    "train_encodings = tokenizer(list(train_texts), list(train_labels), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "val_encodings = tokenizer(list(val_texts), list(val_labels), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\"input_ids\": train_encodings[\"input_ids\"], \"attention_mask\": train_encodings[\"attention_mask\"]},\n",
    "    train_encodings[\"input_ids\"]\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\"input_ids\": val_encodings[\"input_ids\"], \"attention_mask\": val_encodings[\"attention_mask\"]},\n",
    "    val_encodings[\"input_ids\"]\n",
    "))\n",
    "\n",
    "# Batch and shuffle\n",
    "BATCH_SIZE = 8\n",
    "train_dataset = train_dataset.shuffle(len(train_texts)).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdbe1234-7dfe-4119-afa9-b3e92f8c418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1672, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_filetlosrciy.py\", line 91, in tf__call\n        decoder_outputs = ag__.converted_call(ag__.ld(self).decoder, (ag__.ld(decoder_input_ids),), dict(attention_mask=ag__.ld(decoder_attention_mask), encoder_hidden_states=ag__.ld(hidden_states), encoder_attention_mask=ag__.ld(attention_mask), inputs_embeds=ag__.ld(decoder_inputs_embeds), head_mask=ag__.ld(decoder_head_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 65, in tf__call\n        ag__.if_stmt(ag__.and_(lambda: ag__.ld(input_ids) is not None, lambda: ag__.ld(inputs_embeds) is not None), if_body_2, else_body_2, get_state_2, set_state_2, ('input_ids', 'input_shape'), 2)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 62, in else_body_2\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('input_ids', 'input_shape'), 2)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 59, in else_body_1\n        ag__.if_stmt(ag__.ld(inputs_embeds) is not None, if_body, else_body, get_state, set_state, ('input_shape',), 1)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 56, in else_body\n        raise ag__.converted_call(ag__.ld(ValueError), (f'You have to specify either {ag__.ld(err_msg_prefix)}input_ids or {ag__.ld(err_msg_prefix)}inputs_embeds',), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'tft5_for_conditional_generation_4' (type TFT5ForConditionalGeneration).\n    \n    in user code:\n    \n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1395, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 1455, in call  *\n            decoder_outputs = self.decoder(\n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n            raise\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 65, in tf__call\n            ag__.if_stmt(ag__.and_(lambda: ag__.ld(input_ids) is not None, lambda: ag__.ld(inputs_embeds) is not None), if_body_2, else_body_2, get_state_2, set_state_2, ('input_ids', 'input_shape'), 2)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 62, in else_body_2\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('input_ids', 'input_shape'), 2)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 59, in else_body_1\n            ag__.if_stmt(ag__.ld(inputs_embeds) is not None, if_body, else_body, get_state, set_state, ('input_shape',), 1)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 56, in else_body\n            raise ag__.converted_call(ag__.ld(ValueError), (f'You have to specify either {ag__.ld(err_msg_prefix)}input_ids or {ag__.ld(err_msg_prefix)}inputs_embeds',), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'decoder' (type TFT5MainLayer).\n        \n        in user code:\n        \n            File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1395, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 754, in call  *\n                raise ValueError(f\"You have to specify either {err_msg_prefix}input_ids or {err_msg_prefix}inputs_embeds\")\n        \n            ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds\n        \n        \n        Call arguments received by layer 'decoder' (type TFT5MainLayer):\n          • input_ids=None\n          • attention_mask=None\n          • encoder_hidden_states=tf.Tensor(shape=(None, 512, 512), dtype=float32)\n          • encoder_attention_mask=tf.Tensor(shape=(None, 512), dtype=int32)\n          • inputs_embeds=None\n          • head_mask=None\n          • encoder_head_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tft5_for_conditional_generation_4' (type TFT5ForConditionalGeneration):\n      • input_ids={'input_ids': 'tf.Tensor(shape=(None, 512), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 512), dtype=int32)'}\n      • attention_mask=None\n      • decoder_input_ids=None\n      • decoder_attention_mask=None\n      • head_mask=None\n      • decoder_head_mask=None\n      • encoder_outputs=None\n      • past_key_values=None\n      • inputs_embeds=None\n      • decoder_inputs_embeds=None\n      • labels=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39mEPOCHS)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevyyey28q.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1672\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1670\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1672\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_using_dummy_loss:\n\u001b[0;32m   1674\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(y_pred\u001b[38;5;241m.\u001b[39mloss, y_pred\u001b[38;5;241m.\u001b[39mloss, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetlosrciy.py:91\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     90\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mand_(\u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mld(labels) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mand_(\u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mld(decoder_input_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mld(decoder_inputs_embeds) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)), if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdecoder, (ag__\u001b[38;5;241m.\u001b[39mld(decoder_input_ids),), \u001b[38;5;28mdict\u001b[39m(attention_mask\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(decoder_attention_mask), encoder_hidden_states\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(hidden_states), encoder_attention_mask\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(attention_mask), inputs_embeds\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(decoder_inputs_embeds), head_mask\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(decoder_head_mask), past_key_values\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(past_key_values), use_cache\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(use_cache), output_attentions\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(output_attentions), output_hidden_states\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(output_hidden_states), return_dict\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(return_dict), training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     92\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(decoder_outputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py:65\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, encoder_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m     63\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m err_msg_prefix \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merr_msg_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mand_(\u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mld(input_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mlambda\u001b[39;00m: ag__\u001b[38;5;241m.\u001b[39mld(inputs_embeds) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (inputs_embeds,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py:62\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m err_msg_prefix \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merr_msg_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(input_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_1, else_body_1, get_state_1, set_state_1, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py:59\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_2.<locals>.else_body_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m err_msg_prefix \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merr_msg_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(inputs_embeds) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py:56\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_2.<locals>.else_body_1.<locals>.else_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m input_shape\n\u001b[0;32m     55\u001b[0m err_msg_prefix \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mif_exp(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mis_decoder, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.is_decoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(err_msg_prefix)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(err_msg_prefix)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1672, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_filetlosrciy.py\", line 91, in tf__call\n        decoder_outputs = ag__.converted_call(ag__.ld(self).decoder, (ag__.ld(decoder_input_ids),), dict(attention_mask=ag__.ld(decoder_attention_mask), encoder_hidden_states=ag__.ld(hidden_states), encoder_attention_mask=ag__.ld(attention_mask), inputs_embeds=ag__.ld(decoder_inputs_embeds), head_mask=ag__.ld(decoder_head_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 65, in tf__call\n        ag__.if_stmt(ag__.and_(lambda: ag__.ld(input_ids) is not None, lambda: ag__.ld(inputs_embeds) is not None), if_body_2, else_body_2, get_state_2, set_state_2, ('input_ids', 'input_shape'), 2)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 62, in else_body_2\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('input_ids', 'input_shape'), 2)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 59, in else_body_1\n        ag__.if_stmt(ag__.ld(inputs_embeds) is not None, if_body, else_body, get_state, set_state, ('input_shape',), 1)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 56, in else_body\n        raise ag__.converted_call(ag__.ld(ValueError), (f'You have to specify either {ag__.ld(err_msg_prefix)}input_ids or {ag__.ld(err_msg_prefix)}inputs_embeds',), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'tft5_for_conditional_generation_4' (type TFT5ForConditionalGeneration).\n    \n    in user code:\n    \n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1395, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 1455, in call  *\n            decoder_outputs = self.decoder(\n        File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file9b0oo3yi.py\", line 40, in tf__run_call_with_unpacked_inputs\n            raise\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 65, in tf__call\n            ag__.if_stmt(ag__.and_(lambda: ag__.ld(input_ids) is not None, lambda: ag__.ld(inputs_embeds) is not None), if_body_2, else_body_2, get_state_2, set_state_2, ('input_ids', 'input_shape'), 2)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 62, in else_body_2\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('input_ids', 'input_shape'), 2)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 59, in else_body_1\n            ag__.if_stmt(ag__.ld(inputs_embeds) is not None, if_body, else_body, get_state, set_state, ('input_shape',), 1)\n        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\__autograph_generated_file_ym6xoym.py\", line 56, in else_body\n            raise ag__.converted_call(ag__.ld(ValueError), (f'You have to specify either {ag__.ld(err_msg_prefix)}input_ids or {ag__.ld(err_msg_prefix)}inputs_embeds',), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'decoder' (type TFT5MainLayer).\n        \n        in user code:\n        \n            File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1395, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 754, in call  *\n                raise ValueError(f\"You have to specify either {err_msg_prefix}input_ids or {err_msg_prefix}inputs_embeds\")\n        \n            ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds\n        \n        \n        Call arguments received by layer 'decoder' (type TFT5MainLayer):\n          • input_ids=None\n          • attention_mask=None\n          • encoder_hidden_states=tf.Tensor(shape=(None, 512, 512), dtype=float32)\n          • encoder_attention_mask=tf.Tensor(shape=(None, 512), dtype=int32)\n          • inputs_embeds=None\n          • head_mask=None\n          • encoder_head_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tft5_for_conditional_generation_4' (type TFT5ForConditionalGeneration):\n      • input_ids={'input_ids': 'tf.Tensor(shape=(None, 512), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 512), dtype=int32)'}\n      • attention_mask=None\n      • decoder_input_ids=None\n      • decoder_attention_mask=None\n      • head_mask=None\n      • decoder_head_mask=None\n      • encoder_outputs=None\n      • past_key_values=None\n      • inputs_embeds=None\n      • decoder_inputs_embeds=None\n      • labels=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "# Define optimizer and loss function for T5\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 5\n",
    "model.fit(train_dataset, epochs=EPOCHS)\n",
    "\n",
    "print(\"Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4400d-45a3-468e-8645-302ef6e99a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a9001-f4c0-42eb-889a-289e614a690b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
